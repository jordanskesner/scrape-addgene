# Installs
# pip install selenium

# ChromeDriver download
# https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win64/chromedriver-win64.zip

# Imports
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import time


# Initialize driver 
# Specify the path to your chromedriver
#driver_path = "C://Users//jsk33//OneDrive//Github//scrape-addgene//chromedriver-win64//chromedriver.exe"  # Replace with the actual path to the WebDriver
driver_path = ".//chromedriver-win64//chromedriver.exe"
service = Service(driver_path)

# Initialize WebDriver
#driver = webdriver.Chrome(service=service)


#
try:

    # Initialize WebDriver
    driver = webdriver.Chrome(service=service)
    
    # Open the target website
    url = 'https://www.addgene.org/'  # Replace with the website you want to scrape
    driver.get(url)
    
    # Wait for the page to load
    time.sleep(5)  # Adjust based on the website's loading speed
 
    # Locate the search bar element (e.g., by name, id, class, or CSS selector)
    # <input form="search-bar" id="search-text-input" class="suggest-input" aria-expanded="false" aria-haspopup="listbox" type="text" role="combobox" autocomplete="off" placeholder="e.g. 74218, Cas9, transformation protocol" name="q" aria-owns="awesomplete_list_2">
    search_bar = driver.find_element(By.ID, 'search-text-input')  # Replace 'q' with the name of the search input field
    
    # Enter text into the search bar
    search_text = "GFP"  # Replace with the text you want to enter
    search_bar.send_keys(search_text)
    
    # Submit the search (if needed, e.g., by pressing Enter)
    search_bar.send_keys(Keys.RETURN)
    
    # Wait for the results to load
    time.sleep(5)

    # Select the plasmids subcategory
    inplasmids_bar = driver.find_element(By.XPATH, "//span[@class='leaf-label' and text()='in Plasmids']")
    # click it
    inplasmids_bar.click()

    # Wait for the results to load
    time.sleep(5)

    # Optional: Print the title of the resulting page
    print(driver.title)
    
finally:
    # Close the WebDriver
    driver.quit()






<span class="leaf-label">in Plasmids</span>





try:
    # Open the target website
    url = 'https://example.com'  # Replace with the website you want to scrape
    driver.get(url)
    
    # Wait for the page to load
    time.sleep(2)
    
    # Example: Find an element by its tag name
    links = driver.find_elements(By.TAG_NAME, 'a')
    for link in links:
        print(link.text, link.get_attribute('href'))
    
finally:
    # Close the WebDriver
    driver.quit()

